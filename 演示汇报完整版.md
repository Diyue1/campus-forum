# 🎓 软件工程实践项目汇报
## 测试与质量保证体系完整演示

---

## 📋 汇报大纲

1. 持续集成与自动测试框架 ✅
2. 性能测试工具研究（对比2种工具）✅
3. 代码分析工具研究 ✅
4. 测试跟踪与故障管理 ✅
5. 版本控制与配置管理 ✅

---

## 第一部分：持续集成与自动测试框架 (10分钟)

### 演讲内容

"首先，我将展示我们项目的持续集成与自动测试框架。我们的项目是一个校园论坛系统，采用Vue 3 + TypeScript技术栈。"

### 现场演示步骤

#### 1. 展示项目结构
```bash
# 打开终端，展示项目目录
cd "C:\Users\Elliot\Desktop\Software Engineering Practice"
dir
```

**讲解要点**：
- "这是我们的项目根目录，包含了完整的测试框架配置"
- "我们使用Vitest进行单元测试，Playwright进行端到端测试"

#### 2. 展示测试配置文件
```bash
# 打开 vitest.config.ts
code vitest.config.ts
```

**讲解要点**：
- "这是Vitest的配置文件，我们配置了测试环境、覆盖率报告等"
- "测试覆盖率目标设置为90%以上"

#### 3. 运行单元测试
```bash
npm test
```

**讲解要点**：
- "现在运行单元测试，可以看到所有测试用例都通过了"
- "我们有XX个测试用例，覆盖了核心业务逻辑"

#### 4. 查看测试覆盖率
```bash
npm run test:coverage
```

**讲解要点**：
- "生成测试覆盖率报告，可以看到我们达到了91.66%的覆盖率"
- "打开coverage/index.html查看详细报告"

#### 5. 展示CI/CD配置
```bash
# 打开 GitHub Actions 配置
code .github\workflows\ci.yml
```

**讲解要点**：
- "这是我们的CI/CD流水线配置"
- "每次提交代码时，会自动运行代码检查、单元测试、E2E测试和构建"

#### 6. 展示GitHub Actions运行记录
```bash
# 在浏览器中打开GitHub仓库的Actions页面
```

**讲解要点**：
- "这里可以看到每次提交的CI运行记录"
- "所有检查都通过后，代码才能合并到主分支"

---

## 第二部分：性能测试工具研究 (10分钟)

### 演讲内容

"接下来，我将对比展示两种性能测试工具：Lighthouse和自定义性能测试脚本。"

### 工具对比表

| 特性 | Lighthouse | 自定义性能测试 |
|------|-----------|--------------|
| 测试类型 | 网页质量综合评估 | 自定义性能指标 |
| 使用场景 | 开发阶段优化 | 持续监控 |
| 主要指标 | 性能分数、FCP、LCP | 加载时间、资源分析 |
| 优点 | 全面、有改进建议 | 灵活、可定制 |
| 缺点 | 不能模拟高并发 | 需要编写脚本 |

### 现场演示步骤

#### 1. 启动开发服务器
```bash
# 终端1：启动服务器
npm run dev
```

**讲解要点**：
- "首先启动开发服务器，在localhost:3000运行"

#### 2. 运行Lighthouse测试
```bash
# 终端2：运行Lighthouse
npm run test:lighthouse
```

**讲解要点**：
- "Lighthouse会启动Chrome浏览器，自动测试网页性能"
- "测试包括性能、可访问性、最佳实践、SEO四个维度"

#### 3. 查看Lighthouse报告
```bash
# 打开报告
cd reports\lighthouse
# 打开最新的HTML报告
```

**讲解要点**：
- "这是Lighthouse生成的详细报告"
- "性能分数为XX分，FCP为XX毫秒，LCP为XX毫秒"
- "报告还提供了具体的优化建议"

#### 4. 运行自定义性能测试
```bash
# 终端2：运行自定义测试
npm run test:performance
```

**讲解要点**：
- "这是我们自己编写的性能测试脚本，使用Playwright"
- "测试页面加载时间、资源数量、内存使用等指标"

#### 5. 查看性能测试报告
```bash
# 打开报告
cd reports\performance
# 打开最新的HTML报告
```

**讲解要点**：
- "这个报告显示了详细的性能指标"
- "页面加载时间为XX毫秒，资源总大小为XX KB"
- "所有指标都在预设阈值范围内"

#### 6. 对比总结
**讲解要点**：
- "Lighthouse适合全面评估和获取优化建议"
- "自定义测试适合持续监控特定指标"
- "两者结合使用，可以全面保证应用性能"

---

## 第三部分：代码分析工具研究 (8分钟)

### 演讲内容

"现在展示代码分析工具，包括静态分析、动态分析和代码度量。"

### 现场演示步骤

#### 1. 运行ESLint静态分析
```bash
npm run lint
```

**讲解要点**：
- "ESLint是静态代码分析工具，检查代码质量和规范"
- "我们配置了TypeScript、Vue 3的推荐规则"
- "可以看到只有1个警告，代码质量良好"

#### 2. 展示ESLint配置
```bash
code .eslintrc.cjs
```

**讲解要点**：
- "这是ESLint配置文件，定义了代码规范"
- "包括代码风格、最佳实践、TypeScript规则等"

#### 3. 运行安全检查
```bash
npm run lint:security
```

**讲解要点**：
- "这是专门的安全检查，使用eslint-plugin-security"
- "检测常见的安全漏洞，如SQL注入、XSS等"

#### 4. 展示SonarQube配置
```bash
code sonar-project.properties
```

**讲解要点**：
- "SonarQube是企业级代码质量管理平台"
- "可以检测代码异味、技术债务、安全漏洞"
- "这是SonarQube的项目配置文件"

#### 5. 代码度量展示
```bash
# 展示测试覆盖率报告
start coverage\index.html
```

**讲解要点**：
- "代码度量包括测试覆盖率、代码复杂度等"
- "我们的测试覆盖率达到91.66%"
- "语句覆盖率、分支覆盖率、函数覆盖率都在90%以上"

#### 6. 总结代码质量指标

| 指标 | 当前值 | 目标 | 状态 |
|------|--------|------|------|
| 测试覆盖率 | 91.66% | >90% | ✅ |
| ESLint错误 | 0 | 0 | ✅ |
| ESLint警告 | 1 | <5 | ✅ |
| 安全漏洞 | 0 | 0 | ✅ |

---

## 第四部分：测试跟踪与故障管理 (8分钟)

### 演讲内容

"接下来展示测试跟踪与故障管理系统，这是我们自己开发的管理工具。"

### 现场演示步骤

#### 1. 记录测试结果
```bash
node scripts\test-tracker.js record
```

**讲解要点**：
- "这个命令会记录当前的测试运行结果"
- "包括测试数量、通过率、失败的测试用例等"

#### 2. 创建Bug
```bash
node scripts\test-tracker.js bug create "登录页面响应慢" "用户登录时页面响应时间超过3秒" high
```

**讲解要点**：
- "可以通过命令行快速创建Bug"
- "包括标题、描述、严重程度等信息"
- "Bug会自动分配唯一ID"

#### 3. 查看Bug列表
```bash
node scripts\test-tracker.js bug list
```

**讲解要点**：
- "查看所有Bug的列表"
- "显示Bug ID、标题、状态、严重程度等"

#### 4. 更新Bug状态
```bash
node scripts\test-tracker.js bug update BUG-XXXXX resolved "已优化登录逻辑，响应时间降至1秒以内"
```

**讲解要点**：
- "更新Bug状态为已解决"
- "添加解决方案说明"

#### 5. 生成测试报告
```bash
node scripts\test-tracker.js report
```

**讲解要点**：
- "生成完整的测试跟踪报告"
- "包括测试统计、Bug统计、质量评分等"

#### 6. 查看HTML报告
```bash
cd reports\test-tracking
# 打开最新的HTML报告
```

**讲解要点**：
- "这是可视化的测试报告"
- "显示测试趋势、Bug分布、质量指标等"
- "便于团队了解项目质量状况"

#### 7. Bug生命周期说明

```
新建 (open) 
  ↓
处理中 (in-progress)
  ↓
已解决 (resolved)
  ↓
已关闭 (closed)
```

**讲解要点**：
- "Bug有完整的生命周期管理"
- "从创建到关闭，每个状态都有记录"
- "可以统计平均修复时间等指标"

---

## 第五部分：版本控制与配置管理 (8分钟)

### 演讲内容

"最后展示版本控制与配置管理，包括Git工作流和回归测试。"

### 现场演示步骤

#### 1. 展示Git分支策略
```bash
git branch -a
```

**讲解要点**：
- "我们采用Git Flow工作流"
- "main分支用于生产环境"
- "develop分支用于开发"
- "feature分支用于新功能开发"

#### 2. 展示Git Hooks配置
```bash
dir .husky
```

**讲解要点**：
- "我们配置了三个Git钩子"
- "pre-commit: 提交前检查代码质量"
- "commit-msg: 验证提交信息格式"
- "pre-push: 推送前运行完整测试"

#### 3. 查看pre-commit钩子
```bash
type .husky\pre-commit
```

**讲解要点**：
- "pre-commit钩子会自动运行代码检查和测试"
- "确保提交的代码符合质量标准"

#### 4. 演示提交代码流程
```bash
# 创建测试文件
echo "// test" > test-demo.txt
git add test-demo.txt

# 尝试错误格式的提交（会失败）
git commit -m "update"
```

**讲解要点**：
- "提交信息不符合规范，commit-msg钩子会拒绝"
- "必须使用约定式提交格式"

#### 5. 正确的提交方式
```bash
git commit -m "docs: 添加演示文件"
```

**讲解要点**：
- "使用正确的格式：类型(范围): 描述"
- "类型包括：feat, fix, docs, style, refactor, test, chore"

#### 6. 运行回归测试
```bash
npm run test:regression
```

**讲解要点**：
- "回归测试会运行所有单元测试和E2E测试"
- "确保新代码不会破坏现有功能"
- "这是质量保证的重要环节"

#### 7. 清理演示文件
```bash
git reset HEAD test-demo.txt
del test-demo.txt
```

---

## 总结与展望 (5分钟)

### 成果总结

**讲解要点**：

"通过这次项目实践，我们完成了以下工作：

1. **持续集成与自动测试框架** ✅
   - 搭建了完整的CI/CD流水线
   - 实现了自动化测试和部署
   - 测试覆盖率达到91.66%

2. **性能测试工具研究** ✅
   - 对比了Lighthouse和自定义性能测试
   - 建立了性能监控体系
   - 确保应用性能达标

3. **代码分析工具研究** ✅
   - 集成了ESLint静态分析
   - 配置了SonarQube代码质量管理
   - 实现了安全漏洞检测

4. **测试跟踪与故障管理** ✅
   - 开发了测试跟踪系统
   - 实现了Bug生命周期管理
   - 建立了质量度量体系

5. **版本控制与配置管理** ✅
   - 采用Git Flow工作流
   - 配置了Git Hooks自动检查
   - 实现了回归测试机制"

### 项目亮点

1. **自动化程度高**：从代码提交到部署全程自动化
2. **质量保证完善**：多层次的测试和检查机制
3. **工具集成好**：各种工具无缝集成到开发流程
4. **可视化报告**：直观的测试和质量报告

### 技术收获

1. 掌握了现代化的测试框架和工具
2. 理解了持续集成和持续部署的实践
3. 学会了性能测试和优化方法
4. 建立了完整的质量保证体系

### 未来改进方向

1. 提高测试覆盖率到95%以上
2. 增加更多的E2E测试场景
3. 集成更多的性能监控工具
4. 实现自动化的性能基准测试

---

## Q&A 环节

### 常见问题准备

**Q1: 为什么选择Vitest而不是Jest？**
A: Vitest与Vite深度集成，启动速度更快，配置更简单，且完全兼容Jest API。

**Q2: Git Hooks会不会影响开发效率？**
A: 短期看会增加一点时间，但长期能避免很多问题，提高整体效率。紧急情况可以使用--no-verify跳过。

**Q3: 如何保证测试的可靠性？**
A: 我们遵循测试最佳实践，测试独立、可重复，并且在CI环境中运行确保一致性。

**Q4: 性能测试的阈值如何确定？**
A: 基于行业标准和用户体验研究，结合实际情况设定，并持续优化。

**Q5: 如何推广这套体系到团队？**
A: 通过文档、培训和实践，逐步推广。Git Hooks确保每个人都遵循规范。

---

## 附录：演示检查清单

### 演示前准备

- [ ] 确保所有依赖已安装：`npm install`
- [ ] 确保所有测试通过：`npm test`
- [ ] 清理旧的报告文件
- [ ] 准备好浏览器和终端窗口
- [ ] 检查网络连接
- [ ] 准备好GitHub仓库页面

### 演示过程

- [ ] 保持终端输出清晰可见
- [ ] 适当放慢操作速度
- [ ] 边操作边讲解
- [ ] 注意时间控制
- [ ] 准备好应对突发情况

### 演示后

- [ ] 回答问题
- [ ] 分享项目链接
- [ ] 提供文档资料

---

## 备用方案

### 如果网络不好
- 提前录制演示视频
- 准备好截图和报告

### 如果测试失败
- 展示之前成功的报告
- 解释失败原因

### 如果时间不够
- 优先展示核心功能
- 其他部分快速过一遍

---

**祝演示成功！** 🎉
